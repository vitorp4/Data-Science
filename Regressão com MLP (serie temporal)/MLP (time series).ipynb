{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from mlp import MLP\r\n",
    "from processing import patterns, persistance, shift\r\n",
    "from metrics import all_metrics_from_dataframe\r\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "df = pd.read_csv('australia.csv')\r\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\r\n",
    "df = df.set_index('timestamp').rolling(6).mean().iloc[6::6]\r\n",
    "df.index.name = None\r\n",
    "df = df.interpolate(method='polynomial', order=5, axis=0).clip(lower=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "LAGS = 4\r\n",
    "HORIZONS = 6\r\n",
    "INITS = 1 \r\n",
    "HIDDEN_LAYERS = [10]\r\n",
    "ACTIVATION = 'relu'\r\n",
    "OPTIMIZER = 'adam'\r\n",
    "LOSS = 'mse'\r\n",
    "VALIDATION_SPLIT = 0.2\r\n",
    "EPOCHS = 200\r\n",
    "\r\n",
    "CENTRAL = 'KIATAWF1'\r\n",
    "\r\n",
    "serie = df[CENTRAL]\r\n",
    "index = serie.index\r\n",
    "serie.describe()\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    8759.000000\n",
       "mean       14.956560\n",
       "std        10.635132\n",
       "min         0.000000\n",
       "25%         4.750000\n",
       "50%        14.375000\n",
       "75%        25.487500\n",
       "max        30.900000\n",
       "Name: KIATAWF1, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "\r\n",
    "train, test = train_test_split(serie, test_size=.33, shuffle=False)\r\n",
    "train_idx, test_idx = train_test_split(index, test_size=.33, shuffle=False)\r\n",
    "X_train, Y_train = patterns(train, LAGS, HORIZONS, dropnan=True, index=train_idx)\r\n",
    "X_test = patterns(test, LAGS, dropnan=False, index=test_idx)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "model = MLP(n_lags=LAGS, n_horizons=HORIZONS, n_inits=INITS)\r\n",
    "model.build(hidden_layers=HIDDEN_LAYERS, activation=ACTIVATION, optimizer=OPTIMIZER, loss=LOSS)\r\n",
    "model.train(X_train.values, Y_train.values, validation_split=VALIDATION_SPLIT, epochs=EPOCHS)\r\n",
    "pred = model.predict(X_test.values)\r\n",
    "pred.index = test_idx\r\n",
    "pred"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/200\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 29.2671 - val_loss: 22.6184\n",
      "Epoch 2/200\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 19.4450 - val_loss: 18.6772\n",
      "Epoch 3/200\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 16.9924 - val_loss: 17.2983\n",
      "Epoch 4/200\n",
      "147/147 [==============================] - 0s 767us/step - loss: 15.2030 - val_loss: 16.2993\n",
      "Epoch 5/200\n",
      "147/147 [==============================] - 0s 795us/step - loss: 14.5462 - val_loss: 18.1788\n",
      "Epoch 6/200\n",
      "147/147 [==============================] - 0s 676us/step - loss: 14.1590 - val_loss: 16.1575\n",
      "Epoch 7/200\n",
      "147/147 [==============================] - 0s 692us/step - loss: 13.9890 - val_loss: 15.7546\n",
      "Epoch 8/200\n",
      "147/147 [==============================] - 0s 655us/step - loss: 13.9077 - val_loss: 15.7918\n",
      "Epoch 9/200\n",
      "147/147 [==============================] - 0s 699us/step - loss: 13.9440 - val_loss: 18.7575\n",
      "Epoch 10/200\n",
      "147/147 [==============================] - 0s 667us/step - loss: 13.8025 - val_loss: 15.9944\n",
      "Epoch 11/200\n",
      "147/147 [==============================] - 0s 671us/step - loss: 13.6915 - val_loss: 15.4532\n",
      "Epoch 12/200\n",
      "147/147 [==============================] - 0s 679us/step - loss: 13.7205 - val_loss: 15.4618\n",
      "Epoch 13/200\n",
      "147/147 [==============================] - 0s 972us/step - loss: 13.7581 - val_loss: 15.4769\n",
      "Epoch 14/200\n",
      "147/147 [==============================] - 0s 957us/step - loss: 13.4836 - val_loss: 15.6941\n",
      "Epoch 15/200\n",
      "147/147 [==============================] - 0s 692us/step - loss: 13.4136 - val_loss: 18.6407\n",
      "Epoch 16/200\n",
      "147/147 [==============================] - 0s 655us/step - loss: 13.6196 - val_loss: 15.5686\n",
      "Epoch 17/200\n",
      "147/147 [==============================] - 0s 645us/step - loss: 13.3507 - val_loss: 15.4172\n",
      "Epoch 18/200\n",
      "147/147 [==============================] - 0s 697us/step - loss: 13.3242 - val_loss: 15.6517\n",
      "Epoch 19/200\n",
      "147/147 [==============================] - 0s 662us/step - loss: 13.3726 - val_loss: 17.1633\n",
      "Epoch 20/200\n",
      "147/147 [==============================] - 0s 681us/step - loss: 13.4668 - val_loss: 15.3561\n",
      "Epoch 21/200\n",
      "147/147 [==============================] - 0s 701us/step - loss: 13.3283 - val_loss: 16.6143\n",
      "Epoch 22/200\n",
      "147/147 [==============================] - 0s 668us/step - loss: 13.3091 - val_loss: 16.4354\n",
      "Epoch 23/200\n",
      "147/147 [==============================] - 0s 672us/step - loss: 13.2165 - val_loss: 15.5764\n",
      "Epoch 24/200\n",
      "147/147 [==============================] - 0s 691us/step - loss: 13.4181 - val_loss: 15.5231\n",
      "Epoch 25/200\n",
      "147/147 [==============================] - 0s 658us/step - loss: 13.3771 - val_loss: 15.5925\n",
      "Epoch 26/200\n",
      "147/147 [==============================] - 0s 652us/step - loss: 13.2283 - val_loss: 16.0764\n",
      "Epoch 27/200\n",
      "147/147 [==============================] - 0s 654us/step - loss: 13.2125 - val_loss: 15.3835\n",
      "Epoch 28/200\n",
      "147/147 [==============================] - 0s 649us/step - loss: 13.2542 - val_loss: 16.3438\n",
      "Epoch 29/200\n",
      "147/147 [==============================] - 0s 700us/step - loss: 13.3568 - val_loss: 15.5021\n",
      "Epoch 30/200\n",
      "147/147 [==============================] - 0s 682us/step - loss: 13.1346 - val_loss: 15.6170\n",
      "Epoch 1/200\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 93.2108 - val_loss: 44.3005\n",
      "Epoch 2/200\n",
      "147/147 [==============================] - 0s 685us/step - loss: 36.8309 - val_loss: 35.5726\n",
      "Epoch 3/200\n",
      "147/147 [==============================] - 0s 669us/step - loss: 32.1701 - val_loss: 33.1745\n",
      "Epoch 4/200\n",
      "147/147 [==============================] - 0s 687us/step - loss: 31.1057 - val_loss: 33.1973\n",
      "Epoch 5/200\n",
      "147/147 [==============================] - 0s 693us/step - loss: 30.4494 - val_loss: 32.9160\n",
      "Epoch 6/200\n",
      "147/147 [==============================] - 0s 670us/step - loss: 30.3670 - val_loss: 32.8020\n",
      "Epoch 7/200\n",
      "147/147 [==============================] - 0s 719us/step - loss: 30.4802 - val_loss: 33.4299\n",
      "Epoch 8/200\n",
      "147/147 [==============================] - 0s 656us/step - loss: 29.8956 - val_loss: 33.1674\n",
      "Epoch 9/200\n",
      "147/147 [==============================] - 0s 728us/step - loss: 29.8391 - val_loss: 32.9697\n",
      "Epoch 10/200\n",
      "147/147 [==============================] - 0s 674us/step - loss: 29.9678 - val_loss: 32.5508\n",
      "Epoch 11/200\n",
      "147/147 [==============================] - 0s 658us/step - loss: 29.6296 - val_loss: 33.6210\n",
      "Epoch 12/200\n",
      "147/147 [==============================] - 0s 647us/step - loss: 29.8229 - val_loss: 36.5684\n",
      "Epoch 13/200\n",
      "147/147 [==============================] - 0s 644us/step - loss: 29.6632 - val_loss: 34.3807\n",
      "Epoch 14/200\n",
      "147/147 [==============================] - 0s 629us/step - loss: 29.3429 - val_loss: 33.1683\n",
      "Epoch 15/200\n",
      "147/147 [==============================] - 0s 694us/step - loss: 29.4673 - val_loss: 33.8019\n",
      "Epoch 16/200\n",
      "147/147 [==============================] - 0s 699us/step - loss: 29.3724 - val_loss: 32.6300\n",
      "Epoch 17/200\n",
      "147/147 [==============================] - 0s 830us/step - loss: 29.4391 - val_loss: 39.6574\n",
      "Epoch 18/200\n",
      "147/147 [==============================] - 0s 719us/step - loss: 29.1767 - val_loss: 35.5849\n",
      "Epoch 19/200\n",
      "147/147 [==============================] - 0s 692us/step - loss: 29.2543 - val_loss: 32.6240\n",
      "Epoch 20/200\n",
      "147/147 [==============================] - 0s 672us/step - loss: 29.3754 - val_loss: 32.3003\n",
      "Epoch 21/200\n",
      "147/147 [==============================] - 0s 692us/step - loss: 29.3239 - val_loss: 37.9131\n",
      "Epoch 22/200\n",
      "147/147 [==============================] - 0s 651us/step - loss: 29.2883 - val_loss: 32.6816\n",
      "Epoch 23/200\n",
      "147/147 [==============================] - 0s 686us/step - loss: 28.9735 - val_loss: 35.0763\n",
      "Epoch 24/200\n",
      "147/147 [==============================] - 0s 706us/step - loss: 29.3486 - val_loss: 32.9681\n",
      "Epoch 25/200\n",
      "147/147 [==============================] - 0s 658us/step - loss: 28.9052 - val_loss: 32.7043\n",
      "Epoch 26/200\n",
      "147/147 [==============================] - 0s 662us/step - loss: 28.8877 - val_loss: 35.5943\n",
      "Epoch 27/200\n",
      "147/147 [==============================] - 0s 667us/step - loss: 28.7848 - val_loss: 32.6152\n",
      "Epoch 28/200\n",
      "147/147 [==============================] - 0s 632us/step - loss: 28.8036 - val_loss: 33.0884\n",
      "Epoch 29/200\n",
      "147/147 [==============================] - 0s 645us/step - loss: 28.7776 - val_loss: 32.9317\n",
      "Epoch 30/200\n",
      "147/147 [==============================] - 0s 678us/step - loss: 28.8475 - val_loss: 33.1585\n",
      "Epoch 1/200\n",
      "  1/147 [..............................] - ETA: 0s - loss: 480.0726WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0004s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 117.2062 - val_loss: 54.6802\n",
      "Epoch 2/200\n",
      "147/147 [==============================] - 0s 671us/step - loss: 52.2305 - val_loss: 52.1621\n",
      "Epoch 3/200\n",
      "147/147 [==============================] - 0s 674us/step - loss: 47.8194 - val_loss: 46.6253\n",
      "Epoch 4/200\n",
      "147/147 [==============================] - 0s 645us/step - loss: 45.6010 - val_loss: 45.8404\n",
      "Epoch 5/200\n",
      "147/147 [==============================] - 0s 671us/step - loss: 44.4999 - val_loss: 45.6684\n",
      "Epoch 6/200\n",
      "147/147 [==============================] - 0s 646us/step - loss: 43.8635 - val_loss: 47.7344\n",
      "Epoch 7/200\n",
      "147/147 [==============================] - 0s 676us/step - loss: 43.5866 - val_loss: 45.0932\n",
      "Epoch 8/200\n",
      "147/147 [==============================] - 0s 676us/step - loss: 43.1582 - val_loss: 46.4274\n",
      "Epoch 9/200\n",
      "147/147 [==============================] - 0s 668us/step - loss: 42.6739 - val_loss: 45.1526\n",
      "Epoch 10/200\n",
      "147/147 [==============================] - 0s 869us/step - loss: 42.4106 - val_loss: 45.6724\n",
      "Epoch 11/200\n",
      "147/147 [==============================] - 0s 794us/step - loss: 42.3127 - val_loss: 44.8873\n",
      "Epoch 12/200\n",
      "147/147 [==============================] - 0s 713us/step - loss: 42.1712 - val_loss: 45.9609\n",
      "Epoch 13/200\n",
      "147/147 [==============================] - 0s 645us/step - loss: 42.3403 - val_loss: 44.9306\n",
      "Epoch 14/200\n",
      "147/147 [==============================] - 0s 984us/step - loss: 41.9044 - val_loss: 45.2177\n",
      "Epoch 15/200\n",
      "147/147 [==============================] - 0s 755us/step - loss: 41.7289 - val_loss: 49.2822\n",
      "Epoch 16/200\n",
      "147/147 [==============================] - 0s 717us/step - loss: 41.9911 - val_loss: 44.9190\n",
      "Epoch 17/200\n",
      "147/147 [==============================] - 0s 709us/step - loss: 41.7242 - val_loss: 46.3538\n",
      "Epoch 18/200\n",
      "147/147 [==============================] - 0s 754us/step - loss: 41.6384 - val_loss: 49.6450\n",
      "Epoch 19/200\n",
      "147/147 [==============================] - 0s 779us/step - loss: 41.9391 - val_loss: 44.8661\n",
      "Epoch 20/200\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 41.4808 - val_loss: 46.5382\n",
      "Epoch 21/200\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 41.6204 - val_loss: 48.8297\n",
      "Epoch 22/200\n",
      "147/147 [==============================] - 0s 746us/step - loss: 41.5389 - val_loss: 45.6913\n",
      "Epoch 23/200\n",
      "147/147 [==============================] - 0s 766us/step - loss: 41.4411 - val_loss: 47.8721\n",
      "Epoch 24/200\n",
      "147/147 [==============================] - 0s 711us/step - loss: 42.0165 - val_loss: 47.1419\n",
      "Epoch 25/200\n",
      "147/147 [==============================] - 0s 780us/step - loss: 41.3708 - val_loss: 45.1742\n",
      "Epoch 26/200\n",
      "147/147 [==============================] - 0s 841us/step - loss: 41.2267 - val_loss: 46.2111\n",
      "Epoch 27/200\n",
      "147/147 [==============================] - 0s 868us/step - loss: 41.1659 - val_loss: 45.3073\n",
      "Epoch 28/200\n",
      "147/147 [==============================] - 0s 794us/step - loss: 41.3152 - val_loss: 48.9523\n",
      "Epoch 29/200\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 41.2122 - val_loss: 45.9373\n",
      "Epoch 1/200\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 134.7121 - val_loss: 67.3547\n",
      "Epoch 2/200\n",
      "147/147 [==============================] - 0s 777us/step - loss: 62.4994 - val_loss: 59.4632\n",
      "Epoch 3/200\n",
      "147/147 [==============================] - 0s 706us/step - loss: 58.0080 - val_loss: 58.1438\n",
      "Epoch 4/200\n",
      "147/147 [==============================] - 0s 768us/step - loss: 56.1180 - val_loss: 59.0744\n",
      "Epoch 5/200\n",
      "147/147 [==============================] - 0s 702us/step - loss: 55.6183 - val_loss: 62.3631\n",
      "Epoch 6/200\n",
      "147/147 [==============================] - 0s 765us/step - loss: 55.2091 - val_loss: 56.9225\n",
      "Epoch 7/200\n",
      "147/147 [==============================] - 0s 759us/step - loss: 54.5814 - val_loss: 56.4760\n",
      "Epoch 8/200\n",
      "147/147 [==============================] - 0s 767us/step - loss: 54.0644 - val_loss: 61.5079\n",
      "Epoch 9/200\n",
      "147/147 [==============================] - 0s 728us/step - loss: 54.0623 - val_loss: 56.5859\n",
      "Epoch 10/200\n",
      "147/147 [==============================] - 0s 771us/step - loss: 53.6804 - val_loss: 56.7513\n",
      "Epoch 11/200\n",
      "147/147 [==============================] - 0s 723us/step - loss: 53.2336 - val_loss: 59.4406\n",
      "Epoch 12/200\n",
      "147/147 [==============================] - 0s 676us/step - loss: 53.0874 - val_loss: 59.3748\n",
      "Epoch 13/200\n",
      "147/147 [==============================] - 0s 700us/step - loss: 53.2894 - val_loss: 56.1218\n",
      "Epoch 14/200\n",
      "147/147 [==============================] - 0s 713us/step - loss: 53.2008 - val_loss: 57.5030\n",
      "Epoch 15/200\n",
      "147/147 [==============================] - 0s 746us/step - loss: 52.8862 - val_loss: 56.1026\n",
      "Epoch 16/200\n",
      "147/147 [==============================] - 0s 699us/step - loss: 52.6054 - val_loss: 55.5260\n",
      "Epoch 17/200\n",
      "147/147 [==============================] - 0s 699us/step - loss: 52.5851 - val_loss: 58.3520\n",
      "Epoch 18/200\n",
      "147/147 [==============================] - 0s 706us/step - loss: 52.3786 - val_loss: 54.5648\n",
      "Epoch 19/200\n",
      "147/147 [==============================] - 0s 681us/step - loss: 52.2383 - val_loss: 55.2021\n",
      "Epoch 20/200\n",
      "147/147 [==============================] - 0s 678us/step - loss: 52.3843 - val_loss: 54.5419\n",
      "Epoch 21/200\n",
      "147/147 [==============================] - 0s 732us/step - loss: 52.0937 - val_loss: 55.1162\n",
      "Epoch 22/200\n",
      "147/147 [==============================] - 0s 685us/step - loss: 52.1215 - val_loss: 54.5573\n",
      "Epoch 23/200\n",
      "147/147 [==============================] - 0s 738us/step - loss: 52.0311 - val_loss: 57.1631\n",
      "Epoch 24/200\n",
      "147/147 [==============================] - 0s 679us/step - loss: 52.2548 - val_loss: 59.6130\n",
      "Epoch 25/200\n",
      "147/147 [==============================] - 0s 672us/step - loss: 51.8625 - val_loss: 58.9916\n",
      "Epoch 26/200\n",
      "147/147 [==============================] - 0s 710us/step - loss: 51.9617 - val_loss: 57.7763\n",
      "Epoch 27/200\n",
      "147/147 [==============================] - 0s 705us/step - loss: 51.9393 - val_loss: 54.7730\n",
      "Epoch 28/200\n",
      "147/147 [==============================] - 0s 699us/step - loss: 52.3861 - val_loss: 62.6806\n",
      "Epoch 29/200\n",
      "147/147 [==============================] - 0s 706us/step - loss: 52.1300 - val_loss: 57.1643\n",
      "Epoch 30/200\n",
      "147/147 [==============================] - 0s 754us/step - loss: 52.0249 - val_loss: 56.3128\n",
      "Epoch 1/200\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 78.0822 - val_loss: 69.4564\n",
      "Epoch 2/200\n",
      "147/147 [==============================] - 0s 740us/step - loss: 68.6320 - val_loss: 66.7507\n",
      "Epoch 3/200\n",
      "147/147 [==============================] - 0s 719us/step - loss: 67.1336 - val_loss: 65.9411\n",
      "Epoch 4/200\n",
      "147/147 [==============================] - 0s 726us/step - loss: 65.7865 - val_loss: 68.1094\n",
      "Epoch 5/200\n",
      "147/147 [==============================] - 0s 706us/step - loss: 64.7800 - val_loss: 67.5340\n",
      "Epoch 6/200\n",
      "147/147 [==============================] - 0s 692us/step - loss: 63.7796 - val_loss: 72.8492\n",
      "Epoch 7/200\n",
      "147/147 [==============================] - 0s 708us/step - loss: 63.3853 - val_loss: 72.5051\n",
      "Epoch 8/200\n",
      "147/147 [==============================] - 0s 691us/step - loss: 62.9077 - val_loss: 63.4774\n",
      "Epoch 9/200\n",
      "147/147 [==============================] - 0s 713us/step - loss: 62.5444 - val_loss: 65.6289\n",
      "Epoch 10/200\n",
      "147/147 [==============================] - 0s 727us/step - loss: 61.6453 - val_loss: 65.5957\n",
      "Epoch 11/200\n",
      "147/147 [==============================] - 0s 693us/step - loss: 61.7344 - val_loss: 69.3845\n",
      "Epoch 12/200\n",
      "147/147 [==============================] - 0s 723us/step - loss: 61.5581 - val_loss: 63.7114\n",
      "Epoch 13/200\n",
      "147/147 [==============================] - 0s 729us/step - loss: 61.1611 - val_loss: 70.9667\n",
      "Epoch 14/200\n",
      "147/147 [==============================] - 0s 678us/step - loss: 61.1673 - val_loss: 62.6561\n",
      "Epoch 15/200\n",
      "147/147 [==============================] - 0s 936us/step - loss: 61.1832 - val_loss: 68.1994\n",
      "Epoch 16/200\n",
      "147/147 [==============================] - 0s 690us/step - loss: 60.8118 - val_loss: 72.4682\n",
      "Epoch 17/200\n",
      "147/147 [==============================] - 0s 705us/step - loss: 60.6400 - val_loss: 63.1161\n",
      "Epoch 18/200\n",
      "147/147 [==============================] - 0s 687us/step - loss: 60.6215 - val_loss: 70.5575\n",
      "Epoch 19/200\n",
      "147/147 [==============================] - 0s 719us/step - loss: 60.4202 - val_loss: 64.6089\n",
      "Epoch 20/200\n",
      "147/147 [==============================] - 0s 745us/step - loss: 60.4451 - val_loss: 64.8366\n",
      "Epoch 21/200\n",
      "147/147 [==============================] - 0s 708us/step - loss: 60.5847 - val_loss: 65.1330\n",
      "Epoch 22/200\n",
      "147/147 [==============================] - 0s 696us/step - loss: 60.1390 - val_loss: 63.1288\n",
      "Epoch 23/200\n",
      "147/147 [==============================] - 0s 733us/step - loss: 60.1208 - val_loss: 73.9548\n",
      "Epoch 24/200\n",
      "147/147 [==============================] - 0s 726us/step - loss: 60.0050 - val_loss: 64.1365\n",
      "Epoch 1/200\n",
      "  1/147 [..............................] - ETA: 0s - loss: 348.6500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0002s vs `on_train_batch_end` time: 0.0007s). Check your callbacks.\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 103.8813 - val_loss: 83.0035\n",
      "Epoch 2/200\n",
      "147/147 [==============================] - 0s 811us/step - loss: 78.9705 - val_loss: 77.7412\n",
      "Epoch 3/200\n",
      "147/147 [==============================] - 0s 755us/step - loss: 75.7043 - val_loss: 74.9117\n",
      "Epoch 4/200\n",
      "147/147 [==============================] - 0s 742us/step - loss: 74.8602 - val_loss: 75.5559\n",
      "Epoch 5/200\n",
      "147/147 [==============================] - 0s 829us/step - loss: 73.6648 - val_loss: 75.6053\n",
      "Epoch 6/200\n",
      "147/147 [==============================] - 0s 739us/step - loss: 72.7683 - val_loss: 72.9476\n",
      "Epoch 7/200\n",
      "147/147 [==============================] - 0s 719us/step - loss: 72.3102 - val_loss: 72.4513\n",
      "Epoch 8/200\n",
      "147/147 [==============================] - 0s 746us/step - loss: 72.1042 - val_loss: 78.4452\n",
      "Epoch 9/200\n",
      "147/147 [==============================] - 0s 777us/step - loss: 71.5303 - val_loss: 74.1914\n",
      "Epoch 10/200\n",
      "147/147 [==============================] - 0s 768us/step - loss: 71.1774 - val_loss: 77.3987\n",
      "Epoch 11/200\n",
      "147/147 [==============================] - 0s 694us/step - loss: 70.5119 - val_loss: 75.5144\n",
      "Epoch 12/200\n",
      "147/147 [==============================] - 0s 751us/step - loss: 70.4006 - val_loss: 78.9307\n",
      "Epoch 13/200\n",
      "147/147 [==============================] - 0s 699us/step - loss: 70.1363 - val_loss: 72.9336\n",
      "Epoch 14/200\n",
      "147/147 [==============================] - 0s 728us/step - loss: 69.8326 - val_loss: 70.8783\n",
      "Epoch 15/200\n",
      "147/147 [==============================] - 0s 740us/step - loss: 69.5998 - val_loss: 72.5816\n",
      "Epoch 16/200\n",
      "147/147 [==============================] - 0s 713us/step - loss: 69.5312 - val_loss: 71.3208\n",
      "Epoch 17/200\n",
      "147/147 [==============================] - 0s 726us/step - loss: 69.2701 - val_loss: 77.3394\n",
      "Epoch 18/200\n",
      "147/147 [==============================] - 0s 787us/step - loss: 69.3910 - val_loss: 71.2537\n",
      "Epoch 19/200\n",
      "147/147 [==============================] - 0s 708us/step - loss: 69.3821 - val_loss: 69.3639\n",
      "Epoch 20/200\n",
      "147/147 [==============================] - 0s 712us/step - loss: 69.4849 - val_loss: 72.1279\n",
      "Epoch 21/200\n",
      "147/147 [==============================] - 0s 736us/step - loss: 69.1025 - val_loss: 71.4838\n",
      "Epoch 22/200\n",
      "147/147 [==============================] - 0s 755us/step - loss: 68.8516 - val_loss: 72.6842\n",
      "Epoch 23/200\n",
      "147/147 [==============================] - 0s 724us/step - loss: 68.6603 - val_loss: 69.2531\n",
      "Epoch 24/200\n",
      "147/147 [==============================] - 0s 731us/step - loss: 68.5305 - val_loss: 70.0858\n",
      "Epoch 25/200\n",
      "147/147 [==============================] - 0s 699us/step - loss: 68.5862 - val_loss: 75.2069\n",
      "Epoch 26/200\n",
      "147/147 [==============================] - 0s 754us/step - loss: 68.4520 - val_loss: 75.3474\n",
      "Epoch 27/200\n",
      "147/147 [==============================] - 0s 732us/step - loss: 68.3359 - val_loss: 72.6458\n",
      "Epoch 28/200\n",
      "147/147 [==============================] - 0s 727us/step - loss: 68.3558 - val_loss: 70.4668\n",
      "Epoch 29/200\n",
      "147/147 [==============================] - 0s 733us/step - loss: 68.3335 - val_loss: 73.4790\n",
      "Epoch 30/200\n",
      "147/147 [==============================] - 0s 706us/step - loss: 68.0965 - val_loss: 72.3574\n",
      "Epoch 31/200\n",
      "147/147 [==============================] - 0s 716us/step - loss: 67.9801 - val_loss: 75.0973\n",
      "Epoch 32/200\n",
      "147/147 [==============================] - 0s 723us/step - loss: 67.6379 - val_loss: 75.5100\n",
      "Epoch 33/200\n",
      "147/147 [==============================] - 0s 766us/step - loss: 68.0975 - val_loss: 69.2665\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                 t+1        t+2        t+3        t+4  \\\n",
       "2018-09-02 13:00:00+10:00        NaN        NaN        NaN        NaN   \n",
       "2018-09-02 14:00:00+10:00        NaN        NaN        NaN        NaN   \n",
       "2018-09-02 15:00:00+10:00        NaN        NaN        NaN        NaN   \n",
       "2018-09-02 16:00:00+10:00        NaN        NaN        NaN        NaN   \n",
       "2018-09-02 17:00:00+10:00        NaN        NaN        NaN        NaN   \n",
       "...                              ...        ...        ...        ...   \n",
       "2018-12-31 19:00:00+10:00  11.428429   8.552522   8.280828   9.335155   \n",
       "2018-12-31 20:00:00+10:00  12.522225  10.759546   8.920712  11.017819   \n",
       "2018-12-31 21:00:00+10:00  20.365017  11.548759  11.314064  10.957820   \n",
       "2018-12-31 22:00:00+10:00  29.743427  17.888680  11.680586  11.272271   \n",
       "2018-12-31 23:00:00+10:00  28.336702  25.757225  17.195946  11.802961   \n",
       "\n",
       "                                 t+5        t+6  \n",
       "2018-09-02 13:00:00+10:00        NaN        NaN  \n",
       "2018-09-02 14:00:00+10:00        NaN        NaN  \n",
       "2018-09-02 15:00:00+10:00        NaN        NaN  \n",
       "2018-09-02 16:00:00+10:00        NaN        NaN  \n",
       "2018-09-02 17:00:00+10:00        NaN        NaN  \n",
       "...                              ...        ...  \n",
       "2018-12-31 19:00:00+10:00   6.832157   7.834205  \n",
       "2018-12-31 20:00:00+10:00   9.840023  10.626324  \n",
       "2018-12-31 21:00:00+10:00  11.877180  12.396652  \n",
       "2018-12-31 22:00:00+10:00  11.856316  12.073645  \n",
       "2018-12-31 23:00:00+10:00  13.207400  11.230515  \n",
       "\n",
       "[2891 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t+1</th>\n",
       "      <th>t+2</th>\n",
       "      <th>t+3</th>\n",
       "      <th>t+4</th>\n",
       "      <th>t+5</th>\n",
       "      <th>t+6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-09-02 13:00:00+10:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-02 14:00:00+10:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-02 15:00:00+10:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-02 16:00:00+10:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-02 17:00:00+10:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 19:00:00+10:00</th>\n",
       "      <td>11.428429</td>\n",
       "      <td>8.552522</td>\n",
       "      <td>8.280828</td>\n",
       "      <td>9.335155</td>\n",
       "      <td>6.832157</td>\n",
       "      <td>7.834205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 20:00:00+10:00</th>\n",
       "      <td>12.522225</td>\n",
       "      <td>10.759546</td>\n",
       "      <td>8.920712</td>\n",
       "      <td>11.017819</td>\n",
       "      <td>9.840023</td>\n",
       "      <td>10.626324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 21:00:00+10:00</th>\n",
       "      <td>20.365017</td>\n",
       "      <td>11.548759</td>\n",
       "      <td>11.314064</td>\n",
       "      <td>10.957820</td>\n",
       "      <td>11.877180</td>\n",
       "      <td>12.396652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 22:00:00+10:00</th>\n",
       "      <td>29.743427</td>\n",
       "      <td>17.888680</td>\n",
       "      <td>11.680586</td>\n",
       "      <td>11.272271</td>\n",
       "      <td>11.856316</td>\n",
       "      <td>12.073645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 23:00:00+10:00</th>\n",
       "      <td>28.336702</td>\n",
       "      <td>25.757225</td>\n",
       "      <td>17.195946</td>\n",
       "      <td>11.802961</td>\n",
       "      <td>13.207400</td>\n",
       "      <td>11.230515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2891 rows Ã— 6 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "all_metrics_from_dataframe(pred, test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 t+1        t+2        t+3        t+4        t+5        t+6\n",
       "mse        16.847096  38.073647  54.286149  67.166283  79.448995  86.766933\n",
       "rmse        4.104521   6.170385   7.367913   8.195504   8.913417   9.314877\n",
       "bias        0.208349   0.371566   0.061468   0.443864   0.750012   0.957430\n",
       "mae         2.870425   4.515421   5.595819   6.474356   7.156835   7.607125\n",
       "mape        0.383296   0.478418   0.562771   0.568610   0.601860   0.594654\n",
       "corr_coef   0.920516   0.811961   0.717294   0.633720   0.554398   0.496001\n",
       "std_ratio   0.943231   0.882147   0.810602   0.740210   0.714361   0.661711\n",
       "rmsd        4.100689   6.160937   7.367841   8.184888   8.883835   9.267937\n",
       "ss4         0.044721   0.026741   0.015833   0.009217   0.005281   0.003202"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t+1</th>\n",
       "      <th>t+2</th>\n",
       "      <th>t+3</th>\n",
       "      <th>t+4</th>\n",
       "      <th>t+5</th>\n",
       "      <th>t+6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>16.847096</td>\n",
       "      <td>38.073647</td>\n",
       "      <td>54.286149</td>\n",
       "      <td>67.166283</td>\n",
       "      <td>79.448995</td>\n",
       "      <td>86.766933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>4.104521</td>\n",
       "      <td>6.170385</td>\n",
       "      <td>7.367913</td>\n",
       "      <td>8.195504</td>\n",
       "      <td>8.913417</td>\n",
       "      <td>9.314877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias</th>\n",
       "      <td>0.208349</td>\n",
       "      <td>0.371566</td>\n",
       "      <td>0.061468</td>\n",
       "      <td>0.443864</td>\n",
       "      <td>0.750012</td>\n",
       "      <td>0.957430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>2.870425</td>\n",
       "      <td>4.515421</td>\n",
       "      <td>5.595819</td>\n",
       "      <td>6.474356</td>\n",
       "      <td>7.156835</td>\n",
       "      <td>7.607125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape</th>\n",
       "      <td>0.383296</td>\n",
       "      <td>0.478418</td>\n",
       "      <td>0.562771</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.601860</td>\n",
       "      <td>0.594654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corr_coef</th>\n",
       "      <td>0.920516</td>\n",
       "      <td>0.811961</td>\n",
       "      <td>0.717294</td>\n",
       "      <td>0.633720</td>\n",
       "      <td>0.554398</td>\n",
       "      <td>0.496001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ratio</th>\n",
       "      <td>0.943231</td>\n",
       "      <td>0.882147</td>\n",
       "      <td>0.810602</td>\n",
       "      <td>0.740210</td>\n",
       "      <td>0.714361</td>\n",
       "      <td>0.661711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmsd</th>\n",
       "      <td>4.100689</td>\n",
       "      <td>6.160937</td>\n",
       "      <td>7.367841</td>\n",
       "      <td>8.184888</td>\n",
       "      <td>8.883835</td>\n",
       "      <td>9.267937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ss4</th>\n",
       "      <td>0.044721</td>\n",
       "      <td>0.026741</td>\n",
       "      <td>0.015833</td>\n",
       "      <td>0.009217</td>\n",
       "      <td>0.005281</td>\n",
       "      <td>0.003202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "pers = persistance(test, 6, index=test_idx)\r\n",
    "all_metrics_from_dataframe(pers, test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    t+1           t+2           t+3           t+4  \\\n",
       "mse        1.811489e+01  4.177926e+01  6.288383e+01  8.203986e+01   \n",
       "rmse       4.256159e+00  6.463688e+00  7.929933e+00  9.057586e+00   \n",
       "bias      -4.176502e-03 -9.472199e-03 -1.427814e-02 -1.558320e-02   \n",
       "mae        2.836285e+00  4.462377e+00  5.619778e+00  6.571417e+00   \n",
       "mape       1.063826e+14  2.613330e+14  5.337770e+14  8.396594e+14   \n",
       "corr_coef  9.174603e-01  8.095818e-01  7.133768e-01  6.261360e-01   \n",
       "std_ratio  9.999433e-01  9.997471e-01  9.996161e-01  9.997668e-01   \n",
       "rmsd       4.256149e+00  6.463660e+00  7.929888e+00  9.057533e+00   \n",
       "ss4        4.428219e-02  2.684868e-02  1.618661e-02  9.606267e-03   \n",
       "\n",
       "                    t+5           t+6  \n",
       "mse        9.951418e+01  1.157129e+02  \n",
       "rmse       9.975679e+00  1.075699e+01  \n",
       "bias      -1.464846e-02 -1.275409e-02  \n",
       "mae        7.417609e+00  8.126397e+00  \n",
       "mape       1.190349e+15  1.473478e+15  \n",
       "corr_coef  5.465186e-01  4.726759e-01  \n",
       "std_ratio  9.999285e-01  1.000055e+00  \n",
       "rmsd       9.975618e+00  1.075693e+01  \n",
       "ss4        5.575704e-03  3.119849e-03  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t+1</th>\n",
       "      <th>t+2</th>\n",
       "      <th>t+3</th>\n",
       "      <th>t+4</th>\n",
       "      <th>t+5</th>\n",
       "      <th>t+6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>1.811489e+01</td>\n",
       "      <td>4.177926e+01</td>\n",
       "      <td>6.288383e+01</td>\n",
       "      <td>8.203986e+01</td>\n",
       "      <td>9.951418e+01</td>\n",
       "      <td>1.157129e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>4.256159e+00</td>\n",
       "      <td>6.463688e+00</td>\n",
       "      <td>7.929933e+00</td>\n",
       "      <td>9.057586e+00</td>\n",
       "      <td>9.975679e+00</td>\n",
       "      <td>1.075699e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias</th>\n",
       "      <td>-4.176502e-03</td>\n",
       "      <td>-9.472199e-03</td>\n",
       "      <td>-1.427814e-02</td>\n",
       "      <td>-1.558320e-02</td>\n",
       "      <td>-1.464846e-02</td>\n",
       "      <td>-1.275409e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>2.836285e+00</td>\n",
       "      <td>4.462377e+00</td>\n",
       "      <td>5.619778e+00</td>\n",
       "      <td>6.571417e+00</td>\n",
       "      <td>7.417609e+00</td>\n",
       "      <td>8.126397e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape</th>\n",
       "      <td>1.063826e+14</td>\n",
       "      <td>2.613330e+14</td>\n",
       "      <td>5.337770e+14</td>\n",
       "      <td>8.396594e+14</td>\n",
       "      <td>1.190349e+15</td>\n",
       "      <td>1.473478e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corr_coef</th>\n",
       "      <td>9.174603e-01</td>\n",
       "      <td>8.095818e-01</td>\n",
       "      <td>7.133768e-01</td>\n",
       "      <td>6.261360e-01</td>\n",
       "      <td>5.465186e-01</td>\n",
       "      <td>4.726759e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ratio</th>\n",
       "      <td>9.999433e-01</td>\n",
       "      <td>9.997471e-01</td>\n",
       "      <td>9.996161e-01</td>\n",
       "      <td>9.997668e-01</td>\n",
       "      <td>9.999285e-01</td>\n",
       "      <td>1.000055e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmsd</th>\n",
       "      <td>4.256149e+00</td>\n",
       "      <td>6.463660e+00</td>\n",
       "      <td>7.929888e+00</td>\n",
       "      <td>9.057533e+00</td>\n",
       "      <td>9.975618e+00</td>\n",
       "      <td>1.075693e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ss4</th>\n",
       "      <td>4.428219e-02</td>\n",
       "      <td>2.684868e-02</td>\n",
       "      <td>1.618661e-02</td>\n",
       "      <td>9.606267e-03</td>\n",
       "      <td>5.575704e-03</td>\n",
       "      <td>3.119849e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "for h in range(1,HORIZONS-5):\r\n",
    "    plt.plot(pred[f't+{h}'].values[:100], label=f'horizon {h}')\r\n",
    "plt.ylim([0,35])\r\n",
    "plt.legend()\r\n",
    "plt.title(CENTRAL)\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "plot_pacf(test, zero=False)\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d04a2db773ae0d95181b9ba9b69fdac3a0f1c733c775952daf53bafa9b6173ca"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tf': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}